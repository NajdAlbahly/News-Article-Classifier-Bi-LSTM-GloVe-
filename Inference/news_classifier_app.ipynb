{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12285499,"sourceType":"datasetVersion","datasetId":7742575}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"News Article Classification - Inference Script\n==============================================\n\nThis .py script loads a pre-trained Bidirectional LSTM (Bi-LSTM) model with GloVe embeddings\nto classify news articles into one of four categories: World, Sports, Business, or Sci/Tech.\n\nKey Features:\n-------------\n- Uses a cleaned and tokenized AG News dataset vocabulary.\n- Reconstructs the tokenizer on the same training data (AG News).\n- Preprocesses input text with lemmatization and stopword removal.\n- Runs predictions using the trained model (no retraining required).\n- Provides a professional and interactive Gradio web interface.\n\nUsage:\n------\n- Run the script to launch a web app.\n- Paste a news article into the input box.\n- Click \"Classify News Article\" to get the predicted category and model confidence.\n\nDependencies:\n-------------\n- TensorFlow / Keras\n- Hugging Face `datasets`\n- NLTK\n- Gradio","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport re\nfrom datasets import load_dataset\nimport pandas as pd\n\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nimport nltk","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load pre-trained model\nmodel_path = '/kaggle/input/best-agnews-bi-lstm-glove-model-keras/best_agnews_bi_lstm_glove_model.keras'\nmodel = load_model(model_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the dataset for tokenization\ndataset = load_dataset(\"ag_news\")\ntrain_df = dataset['train'].to_pandas()\n\n# Extract raw text\nX_train_raw = train_df['text']\n\n# Recreate and fit the Tokenizer on the training data\ntokenizer = Tokenizer(num_words=20000, oov_token=\"<unk>\")  # Same parameters as during training\ntokenizer.fit_on_texts(X_train_raw)  # Fit the tokenizer on the training data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preprocessing Function\n\nlemmatizer = WordNetLemmatizer()\nstop_words = set(stopwords.words('english'))\n\ndef preprocess_text(text):\n    # Convert to lowercase\n    text = text.lower()\n    # Remove HTML tags (if any)\n    text = re.sub(r'<.*?>', '', text)\n    # Remove URLs\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n    # Remove punctuation and numbers, keeping only letters and spaces\n    text = re.sub(r'[^a-z\\s]', '', text)\n    # Tokenization (split into words)\n    words = text.split()\n    # Remove stopwords and Lemmatize words\n    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words and len(word) > 1]\n    # Join back to string\n    return ' '.join(words)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prediction Function \n\nMAX_SEQUENCE_LENGTH = 200  \nLABEL_MAP = {0: 'World', 1: 'Sports', 2: 'Business', 3: 'Sci/Tech'}\n\ndef predict_news_category(news_text):\n    # 1. Preprocess the raw text\n    processed_text = preprocess_text(news_text)\n    \n    # 2. Convert to sequence using the fitted tokenizer\n    sequence_text = tokenizer.texts_to_sequences([processed_text])\n    \n    # 3. Pad the sequence to the defined max length\n    padded_text = pad_sequences(sequence_text, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n\n    # 4. Make prediction (probabilities for each class) using the pre-trained model\n    prediction_probs = model.predict(padded_text)[0]\n    \n    # 5. Get the predicted class index (highest probability)\n    predicted_class_idx = np.argmax(prediction_probs)\n    \n    # 6. Map the index to its human-readable label\n    predicted_category = LABEL_MAP[predicted_class_idx]\n    \n    # 7. Get the confidence for the predicted class\n    confidence = prediction_probs[predicted_class_idx]\n\n    return predicted_category, confidence","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example Usage\nnew_articles_for_prediction = [\n    \"Scientists announce breakthrough in quantum computing, promising faster processors.\", # Sci/Tech\n    \"New research shows promising results for a vaccine against a rare disease.\", # Sci/Tech\n    \"Messi scored a last-minute goal to win the FIFA World Cup for Argentina. The stadium erupted in cheers as fans celebrated the historic victory in Qatar.\",# Sports\n    \"Political tensions rise in the Middle East after recent border skirmishes.\" # World\n]\n\n# Make predictions\nfor i, article in enumerate(new_articles_for_prediction):\n    category, confidence = predict_news_category(article)\n    print(f\"\\n--- Article {i+1} ---\")\n    print(f\"Text: '{article}'\")\n    print(f\"Predicted Category: {category} (Confidence: {confidence:.2f})\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install gradio","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gradio as gr\n\n# Prediction Function for Gradio \n\ndef classify_news(news_text):\n    \"\"\"\n    Predicts the category of a given news article text.\n    \"\"\"\n    # Defensive check: ensure model and tokenizer are available.\n    # In your training notebook, they should be, but it's good practice.\n    if 'model' not in globals() or model is None:\n        return \"Error: Model not loaded. Please ensure training completed successfully.\", 0.0, {}\n    if 'tokenizer' not in globals() or tokenizer is None:\n        return \"Error: Tokenizer not available. Please ensure it was fitted.\", 0.0, {}\n    if 'MAX_SEQUENCE_LENGTH' not in globals():\n        return \"Error: MAX_SEQUENCE_LENGTH not defined.\", 0.0, {}\n    if 'LABEL_MAP' not in globals():\n        return \"Error: LABEL_MAP not defined.\", 0.0, {}\n    if 'preprocess_text' not in globals():\n        return \"Error: preprocess_text function not defined.\", 0.0, {}\n\n\n    # 1. Preprocess the raw text\n    processed_text = preprocess_text(news_text)\n\n    # 2. Convert to sequence using the fitted tokenizer\n    sequence_text = tokenizer.texts_to_sequences([processed_text])\n\n    # 3. Pad the sequence to the defined max length\n    padded_text = pad_sequences(sequence_text, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n\n    # 4. Make prediction (probabilities for each class)\n    # verbose=0 hides the progress bar during prediction for a cleaner interface\n    prediction_probs = model.predict(padded_text, verbose=0)[0]\n\n    # 5. Get the predicted class index (highest probability)\n    predicted_class_idx = np.argmax(prediction_probs)\n\n    # 6. Map the index to its human-readable label\n    predicted_category = LABEL_MAP[predicted_class_idx]\n\n    # 7. Get the confidence for the predicted class\n    confidence = prediction_probs[predicted_class_idx]\n\n    # Prepare all probabilities as a dictionary for Gradio's gr.Label\n    all_probs_dict = {LABEL_MAP[i]: float(prob) for i, prob in enumerate(prediction_probs)}\n\n    # Gradio expects string for confidence if output type is Textbox\n    return predicted_category, f\"{confidence:.2f}\", all_probs_dict\n\n# --- Build Gradio Interface (the part you already have) ---\nif model is not None and tokenizer is not None:\n    print(\"\\nBuilding Gradio Interface...\")\n    iface = gr.Interface(\n        fn=classify_news,\n        inputs=gr.Textbox(lines=5, placeholder=\"Enter a news article here...\", label=\"News Article Text\"),\n        outputs=[\n            gr.Textbox(label=\"Predicted Category\"),\n            gr.Textbox(label=\"Confidence\"),\n            gr.Label(label=\"All Category Probabilities\")\n        ],\n        title=\"News Article Classifier (Bi-LSTM + GloVe)\",\n        description=(\n            \"Enter a news article and let the Bidirectional LSTM model classify it into one of four categories: \"\n            \"World, Sports, Business, or Sci/Tech. The model uses GloVe pre-trained word embeddings.\"\n        ),\n        examples=[\n            [\"Global leaders meet to discuss climate change initiatives and renewable energy policies.\"],\n            [\"Messi scores hat-trick as Barcelona wins the Champions League final.\"],\n            [\"Tech giants report record quarterly earnings driven by AI investments and cloud services.\"],\n            [\"Scientists announce breakthrough in quantum computing, promising faster processors.\"],\n            [\"The stock market experienced a sharp decline following unexpected inflation data.\"]\n        ]\n    )\n\n    print(\"\\nLaunching Gradio App...\")\n    iface.launch(share=True)\n    print(\"Gradio app launched. Look for the public URL above.\")\nelse:\n    print(\"\\nGradio app cannot be launched because the model or tokenizer failed to load (check previous cells).\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}